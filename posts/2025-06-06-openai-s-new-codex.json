{
  "id": "2025-06-06-openai-s-new-codex",
  "title": "OpenAI’s New Codex",
  "date": "2025-06-06T18:59:00.000Z",
  "categories": [
    "Tech"
  ],
  "thumbnail": "https://images.ctfassets.net/kftzwdyauwt9/1ISt9FUc43tzxBhuR4xulT/0d13cee43ef46f11189b563dc2fa101b/Codex_LP_02_v3.png?w=3840&q=90&fm=webp",
  "images": [],
  "content": "<p data-start=\"246\" data-end=\"475\">OpenAI’s Codex just got a major upgrade and it’s not just a code generator anymore. Now powered by GPT-4o, it is meant to act more like a <em data-start=\"376\" data-end=\"393\">pair programmer</em>&nbsp;that can explain, debug, refactor, and even interpret UI screenshots or diagrams.</p>\n<p data-start=\"477\" data-end=\"630\">I wanted to quickly explore how the new Codex stacks up against other popular tools:</p>\n<hr data-start=\"632\" data-end=\"635\">\n<h3 data-start=\"637\" data-end=\"667\"><strong data-start=\"644\" data-end=\"665\">Codex vs. Copilot</strong></h3>\n<p data-start=\"668\" data-end=\"931\">Copilot is great for fast, inline suggestions, especially inside VS Code. But Codex (especially via ChatGPT Pro) excels at <span data-start=\"792\" data-end=\"812\" style=\"\">multi-file logic</span>, <span data-start=\"814\" data-end=\"829\" style=\"\">refactoring</span>, and <span data-start=\"835\" data-end=\"855\" style=\"\">code explanation</span>. It’s like having a senior dev who’s great at talking through architecture.</p>\n<h3 data-start=\"933\" data-end=\"962\"><strong data-start=\"940\" data-end=\"960\">Codex vs. Claude</strong></h3>\n<p data-start=\"963\" data-end=\"1222\">Claude 3 Opus has a massive context window (~200K tokens) and excels at <span data-start=\"1035\" data-end=\"1051\" style=\"\">code reviews</span>, <span data-start=\"1053\" data-end=\"1061\" style=\"\">docs</span>, and <span data-start=\"1067\" data-end=\"1092\" style=\"\">system-level analysis</span>. But Codex brings a more <span data-start=\"1118\" data-end=\"1142\" style=\"\">interactive workflow. </span><span data-start=\"1118\" data-end=\"1142\" style=\"\">Y</span>ou can upload files, run code in the interpreter, and get step-by-step help.</p>\n<h3 data-start=\"1224\" data-end=\"1253\"><strong data-start=\"1231\" data-end=\"1251\">Codex vs. Cursor</strong></h3>\n<p data-start=\"1254\" data-end=\"1501\">Cursor is like a next-gen IDE with AI built in. It is extremely fast, project-aware, and amazing for day-to-day coding. Codex isn’t as tightly embedded in the IDE, but it’s more <span data-start=\"1423\" data-end=\"1500\" style=\"\">versatile for</span><span data-start=\"1423\" data-end=\"1500\" style=\"\"> debugging, test writing, and architecture-level discussions</span>.</p>\n<hr data-start=\"1503\" data-end=\"1506\">\n<h3 data-start=\"1508\" data-end=\"1554\"><strong data-start=\"1516\" data-end=\"1552\">Under the Hood (Tech Highlights)</strong></h3>\n<ul data-start=\"1555\" data-end=\"2036\">\n<li data-start=\"1555\" data-end=\"1665\">\n<p data-start=\"1557\" data-end=\"1665\"><strong data-start=\"1557\" data-end=\"1576\">Context window:</strong> Codex via GPT-4o supports up to ~128K tokens, letting it reason across large codebases</p>\n</li>\n<li data-start=\"1666\" data-end=\"1813\">\n<p data-start=\"1668\" data-end=\"1813\"><strong data-start=\"1668\" data-end=\"1696\">File upload + execution:</strong> You can upload entire projects, execute code snippets, and analyze runtime output with the built-in Python sandbox</p>\n</li>\n<li data-start=\"1814\" data-end=\"1911\">\n<p data-start=\"1816\" data-end=\"1911\"><strong data-start=\"1816\" data-end=\"1832\">Multi-modal:</strong> It can “see” including screenshots of code, whiteboards, UI design, or error messages</p>\n</li>\n<li data-start=\"1912\" data-end=\"2036\">\n<p data-start=\"1914\" data-end=\"2036\"><strong data-start=\"1914\" data-end=\"1939\">Memory (coming soon):</strong> Codex will eventually remember your coding style, project history, and workflows across sessions</p></li></ul>"
}